# 告警分组(Grouping)


# 告警分组(Grouping)

## 1. 定义三个报警规则：

```
[root@prometheus-server ~]# vim /etc/prometheus/rules/node_alerts.yml 

groups:
- name: node_alerts
  rules:
  - alert: InstanceDown
    expr: up{job='node'} == 0
    for: 2m
    labels:
      severity: "critical"
      env: dev
    annotations:
      summary: Host {{ $labels.instance }} of {{ $labels.job }} is Down!
  - alert: OSLoad
    expr: node_load1 > 1
    for: 2m
    labels:
      severity: "warning"
      env: dev
    annotations:
      summary: "主机 {{ $labels.instance }} 负载大于 1"
      description: "当前值: {{ $value }}"
  - alert: HightCPU
    expr: 100-avg(irate(node_cpu_seconds_total{mode="idle"}[1m])) by(instance)*100 > 10
    for: 2m
    labels:
      severity: "warning"
    annotations:
      summary: "主机 {{ $labels.instance }} of CPU 使用率大于10%!"
      description: "当前值: {{ $value }}%"

```

以上3个报警规则，node_alerts是监控node_exporter服务状态，OSLoad是监控系统负载，HightCPU是监控系统cpu使用率，前两个有标签env: dev,后面2个有标签 severity: "warning",重启Prometheus服务，可以看到监控规则

## 2. 定义alertmanager报警组

```
[root@prometheus-server ~]# vim /etc/alertmanager/alertmanager.ymlglobal:
  smtp_smarthost: 'smtp.163.com:25'
  smtp_from: '****@163.com'
  smtp_auth_username: '****@163.com'
  smtp_auth_password: '****'   ## 授权码
  smtp_require_tls: false

route:
  group_by: ['env']    ### 以标签env分组，拥有labels为env的规则，如果在指定时间同时报警，报警信息会合并为一条进行发送
  group_wait: 10s　　   ### 组报警等待，等待该组中有没有其它报警  group_interval: 30s  ### 组报警时间间隔
  repeat_interval: 2m  ### 重复报警时间，这个生产中跟据服务选择合适的时间
  receiver: dev-mail ## 接收者

receivers:
- name: 'dev-mail'   ## 对应上面的接收者
  email_configs:
  - to: '****@vanje.com.cn'
```

分组总结：

　　1、alertmanager跟据标签进行分组时，应该选择合适的标签，标签可以自定义，也可以使用默认的标签。

　　2、alertmanager报警分组，可以有效减少告警邮件数，但是仅是在同一个时间段报警，同一个组的告警信息才会合并发送。